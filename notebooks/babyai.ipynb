{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Environment Development (\"BabyAI-Text\")\n",
        "\n",
        "This notebook builds the BabyAI ACT-PRM environment, inspects the real state, renders the prompt with tools, and shows the gold trajectory. This is a compact setup similar to the exmaple notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_HOME\"] = os.path.expanduser(\"~/.cache/huggingface\")\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.expanduser(\"~/.cache/huggingface/transformers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/madisonho/Documents/act-prm-tinker/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/madisonho/Documents/act-prm-tinker/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from omegaconf import OmegaConf\n",
        "from rich import print as rich_print\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Get a tokenizer\n",
        "model_config = OmegaConf.load(\"../configs/model/hf_qwen3_4b_inst_2507.yaml\")\n",
        "# Override cache_dir to a writable path (config defaults to /scr/...)\n",
        "model_config.model_config[\"cache_dir\"] = os.path.expanduser(\"~/.cache/huggingface/models\")\n",
        "\n",
        "hf_tokenizer = AutoTokenizer.from_pretrained(**model_config.model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rich_print_messages(\n",
        "    msg_text: str,\n",
        "    bos_token: str = \"<|im_start|>\",\n",
        "    eos_token: str = \"<|im_end|>\\n\",\n",
        "    tool_call_bos_token: str = \"<tool_call>\",\n",
        "    tool_call_eos_token: str = \"</tool_call>\",\n",
        "    tool_response_bos_token: str = \"<tool_response>\",\n",
        "    tool_response_eos_token: str = \"</tool_response>\",\n",
        "):\n",
        "    # Split into messages\n",
        "    messages = msg_text.split(eos_token)\n",
        "\n",
        "    system_bos = f\"{bos_token}system\"\n",
        "    user_bos = f\"{bos_token}user\"\n",
        "    assistant_bos = f\"{bos_token}assistant\"\n",
        "\n",
        "    for ix, message in enumerate(messages):\n",
        "        # system prompt\n",
        "        if message.startswith(system_bos):\n",
        "            messages[ix] = f\"[bright_yellow]{message}[/bright_yellow]\"\n",
        "        # user messages\n",
        "        elif message.startswith(user_bos):\n",
        "            messages[ix] = f\"[bright_red]{message}[/bright_red]\"\n",
        "        # assistant messages\n",
        "        elif message.startswith(assistant_bos):\n",
        "            messages[ix] = f\"[bright_green]{message}[/bright_green]\"\n",
        "\n",
        "        # tool calls\n",
        "        if tool_call_bos_token in messages[ix] and tool_call_eos_token in messages[ix]:\n",
        "            messages[ix] = messages[ix].replace(tool_call_bos_token, f\"[bright_cyan]{tool_call_bos_token}\")\n",
        "            messages[ix] = messages[ix].replace(tool_call_eos_token, f\"{tool_call_eos_token}[/bright_cyan]\")\n",
        "        # tool responses\n",
        "        if tool_response_bos_token in messages[ix] and tool_response_eos_token in messages[ix]:\n",
        "            messages[ix] = messages[ix].replace(tool_response_bos_token, f\"[bright_magenta]{tool_response_bos_token}\")\n",
        "            messages[ix] = messages[ix].replace(tool_response_eos_token, f\"{tool_response_eos_token}[/bright_magenta]\")\n",
        "\n",
        "    msgs_text = eos_token.join(messages)\n",
        "    try:\n",
        "        rich_print(msgs_text)\n",
        "    except Exception:\n",
        "        print(msgs_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BabyAI-Text (ACT-PRM)\n",
        "\n",
        "We now build the BabyAI environment and inspect the real state plus the tool schema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/madisonho/Documents/act-prm-tinker/.venv/lib/python3.12/site-packages/gym/envs/registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
            "  fn()\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "babyai_text package is required for BabyAI-Text. See https://github.com/flowersteam/Grounding_LLMs_with_online_RL/tree/main/babyai-text",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/act-prm-tinker/src/act_prm/environments/babyai_text/env.py:23\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbabyai_text\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401  # used by gym.make\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbabyai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bot\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'babyai_text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mact_prm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvironments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_env\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m babyai_env = \u001b[43mget_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbabyai_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBabyAI-MixedTestLocal-v0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_val_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m babyai_state = babyai_env.reset()\n\u001b[32m     15\u001b[39m babyai_state.system_prompt, babyai_state.new_messages[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m400\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/act-prm-tinker/src/act_prm/environments/__init__.py:69\u001b[39m, in \u001b[36mget_env\u001b[39m\u001b[34m(name, is_async, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m AsyncBabyAiTextEnv(**kwargs)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbabyai_text\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BabyAiTextEnv\n\u001b[32m     70\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m BabyAiTextEnv(**kwargs)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSorry invalid environment: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/act-prm-tinker/src/act_prm/environments/babyai_text/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mBabyAI-Text environment\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BabyAiTextEnv, AsyncBabyAiTextEnv\n\u001b[32m      7\u001b[39m __all__ = [\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBabyAiTextEnv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAsyncBabyAiTextEnv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/act-prm-tinker/src/act_prm/environments/babyai_text/env.py:26\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbabyai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bot\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbabyai_text package is required for BabyAI-Text. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/flowersteam/Grounding_LLMs_with_online_RL/tree/main/babyai-text\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environment\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EnvironmentState, EnvironmentStepResult\n",
            "\u001b[31mImportError\u001b[39m: babyai_text package is required for BabyAI-Text. See https://github.com/flowersteam/Grounding_LLMs_with_online_RL/tree/main/babyai-text"
          ]
        }
      ],
      "source": [
        "from act_prm.environments import get_env\n",
        "\n",
        "babyai_env = get_env(\n",
        "    name=\"babyai_text\",\n",
        "    env_name=\"BabyAI-MixedTestLocal-v0\",\n",
        "    num_train_samples=3,\n",
        "    num_val_samples=1,\n",
        "    num_test_samples=1,\n",
        "    max_turns=20,\n",
        "    seed=0,\n",
        ")\n",
        "\n",
        "babyai_state = babyai_env.reset()\n",
        "\n",
        "babyai_state.system_prompt, babyai_state.new_messages[0][\"content\"][:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = {\"role\": \"system\", \"content\": babyai_state.system_prompt}\n",
        "\n",
        "messages = hf_tokenizer.apply_chat_template(\n",
        "    [system_message] + babyai_state.new_messages,\n",
        "    tokenize=False,\n",
        "    tools=babyai_state.tools,\n",
        ")\n",
        "rich_print_messages(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First few steps of the gold trajectory (user -> assistant -> tool -> ...)\n",
        "babyai_state.action_trajectory[:6]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "act-prm (py3.12)",
      "language": "python",
      "name": "act-prm"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
